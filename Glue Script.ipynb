{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.functions import when,udf,lit,split,current_timestamp\n",
    "import re\n",
    "\n",
    "## @params: [JOB_NAME]\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME'])\n",
    "\n",
    "sc = SparkContext()\n",
    "glueContext = GlueContext(sc)\n",
    "spark = glueContext.spark_session\n",
    "job = Job(glueContext)\n",
    "job.init(args['JOB_NAME'], args)\n",
    "\n",
    "\n",
    "## @type: DataSource\n",
    "## @args: [database = \"aroa-dw-pedro\", table_name = \"sources\", transformation_ctx = \"<transformation_ctx>\"]\n",
    "## @return: sources\n",
    "## @inputs: []\n",
    "sources = glueContext.create_dynamic_frame.from_catalog(database = \"aroa-dw-pedro\", table_name = \"sources\", transformation_ctx = \"sources\")\n",
    "sourcesDF = sources.toDF()\n",
    "\n",
    "## @type: DataSource\n",
    "## @args: [database = \"aroa-dw-pedro\", table_name = \"rules\", transformation_ctx = \"rules\"]\n",
    "## @return: rules\n",
    "## @inputs: []\n",
    "rules = glueContext.create_dynamic_frame.from_catalog(database = \"aroa-dw-pedro\", table_name = \"rules\", transformation_ctx = \"rules\")\n",
    "rulesDF = rules.toDF()\n",
    "\n",
    "## @type: DataSource\n",
    "## @args: [database = \"aroa-dw-pedro\", table_name = \"targets\", transformation_ctx = \"targets\"]\n",
    "## @return: targets\n",
    "## @inputs: []\n",
    "targets = glueContext.create_dynamic_frame.from_catalog(database = \"aroa-dw-pedro\", table_name = \"targets\", transformation_ctx = \"targets\")\n",
    "targetsDF = targets.toDF()\n",
    "\n",
    "sources = {}\n",
    "rules = {}\n",
    "targets = {}\n",
    "\n",
    "for x in sourcesDF.collect():\n",
    "    sources[x['source_var']] = x.asDict()\n",
    "\n",
    "for x in rulesDF.collect():\n",
    "    rules[x['rule_name']] = x.asDict()\n",
    "    \n",
    "for x in targetsDF.collect():\n",
    "    targets[x['target_var']] = x.asDict()\n",
    "\n",
    "def setNewValue(severity,df,oldColumn,newColumn,default):\n",
    "    \n",
    "    if severity.upper() == 'CRITICAL':\n",
    "        interupt = df.filter(df[newColumn]==False).count()\n",
    "        if interupt:\n",
    "            sys.exit()\n",
    "    elif severity.upper() == 'NONE':\n",
    "        result = df\n",
    "        return result\n",
    "    \n",
    "    result = df.withColumn('severity', when(df[newColumn],'Success').otherwise(severity))\n",
    "    result = result.withColumn(newColumn, when(df[newColumn],df[oldColumn]).otherwise(default))\n",
    "    \n",
    "    return result\n",
    "\n",
    "def checkRegex(name,df,column,exp):\n",
    "    temp = df.withColumn('ptemp', df[column])\n",
    "    result = temp.withColumn(name, temp.ptemp.rlike(exp)).drop('ptemp')\n",
    "    \n",
    "    return result\n",
    "\n",
    "def checkLink(name,df1,column1,df2,column2):\n",
    "    \n",
    "    # Rename the column in the second dataframe to avoid ambiguity\n",
    "    temp = df2.withColumnRenamed(column2,'ptemp').select('ptemp')\n",
    "    \n",
    "    # Execute the left join to check links\n",
    "    case = df1.join(temp, df1[column1] == temp.ptemp, 'left')\n",
    "    \n",
    "    # Create the column with true or false argument according to null values in left join\n",
    "    result = case.withColumn(name, when(case.ptemp.isNull(),False).otherwise(True)).drop('ptemp')\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Define if the value is 4 numerical digits\n",
    "def isYear(arg):\n",
    "    if re.match('\\d\\d\\d\\d$', arg):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Define if the value is a number in a 1-31 range    \n",
    "def isDay(arg):    \n",
    "    if re.match('^\\d{1,2}$', arg):\n",
    "        if int(arg)>0 and int(arg)<=31:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Define if the value is considerable as a month and return it in a numerical format\n",
    "def isMonth(arg):\n",
    "    months = ['JANUARY','FEBRUARY','MARCH','APRIL','MAY','JUNE','JULY','SEPTEMBER','OCTOBER','NOVEMBER','DECEMBER']\n",
    "    \n",
    "    #Check if the month is in 99 format and between 1-12\n",
    "    if re.match('^\\d{1,2}$', arg):\n",
    "        if int(arg)>=1 and int(arg)<=12:\n",
    "            return arg\n",
    "        else:\n",
    "            return arg\n",
    "    \n",
    "    #Check if the month correspond to one of the preset values\n",
    "    elif any(re.match('^'+arg.upper(),month) for month in months):\n",
    "        month = next(i+1 for i,month in enumerate(months) if re.match('^'+arg.upper(),month))\n",
    "        return \"{0:0=2d}\".format(month)\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def getDate(row):    \n",
    "    if isYear(row[0]) and isMonth(row[1]) and isDay(row[2]):\n",
    "        return row[0]+'-'+str(isMonth(row[1]))+'-'+row[2]\n",
    "        \n",
    "    elif isDay(row[0]) and isMonth(row[1]) and isYear(row[2]):\n",
    "        return row[2]+'-'+str(isMonth(row[1]))+'-'+row[0]\n",
    "        \n",
    "    elif isMonth(row[0]) and isDay(row[1]) and isYear(row[2]):\n",
    "        return row[2]+'-'+str(isMonth(row[0]))+'-'+row[1]\n",
    "        \n",
    "    else:\n",
    "        return None\n",
    "getDateUDF = udf(getDate)\n",
    "\n",
    "def transformDateFormat(name,df,column):\n",
    "    case = split(column,'\\W').alias(name)\n",
    "    \n",
    "    result = df.withColumn(name, getDateUDF(case))\n",
    "    \n",
    "    return result\n",
    "    \n",
    "# ============================================================================================================================\n",
    "# ============================================================================================================================    \n",
    "# ============================================================================================================================    \n",
    "\n",
    "df_source = {}\n",
    "df = {}\n",
    "\n",
    "# Load Dataframes\n",
    "for source in sources:\n",
    "    table_source = sources[source]['table_source']\n",
    "    database_source = sources[source]['database_source']\n",
    "    \n",
    "    if table_source not in df_source:\n",
    "        print(database_source,table_source)\n",
    "        load = glueContext.create_dynamic_frame.from_catalog(database = database_source, table_name = table_source, transformation_ctx = \"load\")\n",
    "        df_source[table_source] = load.toDF()\n",
    "        \n",
    "    df[sources[source]['source_var']] = df_source[table_source]\n",
    "    \n",
    "# ============================================================================================================================\n",
    "# ============================================================================================================================    \n",
    "# ============================================================================================================================    \n",
    "    \n",
    "# Load rules\n",
    "for rule in rules:\n",
    "    \n",
    "    rule_name = rules[rule]['rule_name']\n",
    "    source_var = rules[rule]['source_var']\n",
    "    function_name = rules[rule]['func_name']\n",
    "    arg = rules[rule]['arg']\n",
    "    default = rules[rule]['default_value']\n",
    "    severity = rules[rule]['severity']\n",
    "    target_var = rules[rule]['target_var']\n",
    "    dq_dim = rules[rule]['dq_dim']\n",
    "    column = sources[source_var]['column_source']\n",
    "    dataFrame = df[source_var]\n",
    "    \n",
    "    if function_name == 'checkRegex':\n",
    "        \n",
    "        df[target_var] = checkRegex(rule_name, dataFrame, column, arg)\n",
    "        \n",
    "    elif function_name == 'checkLink':\n",
    "        \n",
    "        dataFrame2 = df[arg]\n",
    "        column2 = sources[arg]['column_source']\n",
    "        \n",
    "        df[target_var] = checkLink(rule_name,dataFrame,column,dataFrame2,column2)\n",
    "        \n",
    "    elif function_name == 'transformDateFormat':\n",
    "        \n",
    "        df[target_var] = transformDateFormat(rule_name,dataFrame,column)\n",
    "   \n",
    "    else: \n",
    "        break\n",
    "        \n",
    "    if target_var not in sources:\n",
    "        sources[target_var] = sources[source_var]\n",
    "        sources[target_var]['column_source'] = rule_name\n",
    "            \n",
    "    df[target_var] = setNewValue(severity,df[target_var],column,rule_name,default)\n",
    "    df[target_var] = df[target_var].withColumn('dq_dim', lit(dq_dim))\n",
    "    df[target_var] = df[target_var].withColumn('rule', lit(rule_name))\n",
    "    \n",
    "for x in df:\n",
    "    if 'severity' in df[x].columns:\n",
    "        data_source = 'SALES'\n",
    "        print(x)\n",
    "        dataset = sources[x]['table_source']\n",
    "        key_nm = sources[x]['df_id']\n",
    "        field_nm = sources[x]['column_source']\n",
    "        \n",
    "        \n",
    "        df[x] = df[x].withColumn('processing_dttm', current_timestamp())\n",
    "        df[x] = df[x].withColumn('data_source', lit(data_source))\n",
    "        df[x] = df[x].withColumn('dataset', lit(dataset))\n",
    "        df[x] = df[x].withColumn('data_domain', lit(dataset))\n",
    "        df[x] = df[x].withColumn('key_nm', lit(key_nm))\n",
    "        df[x] = df[x].withColumn('key_val', df[x][key_nm])\n",
    "        df[x] = df[x].withColumn('field_nm', lit(field_nm))\n",
    "        df[x] = df[x].withColumn('field_value', df[x][field_nm])\n",
    "        df[x] = df[x].withColumn('dq_rule_result', df[x]['severity'])\n",
    "        \n",
    "        target_frame = DynamicFrame.fromDF(df[x], glueContext, \"target_frame\")\n",
    "        \n",
    "        ## @type: ApplyMapping\n",
    "        ## @args: [mappings = [(\"processing_dttm\",\"string\",\"processing_dttm\",\"string\"),(\"data_source\",\"string\",\"data_source\",\"string\"),(\"dataset\",\"string\",\"dataset\",\"string\"),(\"data_domain\",\"string\",\"data_domain\",\"string\"),(\"key_nm\",\"string\",\"key_nm\",\"string\"),(\"key_value\",\"bigint\",\"key_value\",\"bigint\"),(\"field_nm\",\"string\",\"field_nm\",\"string\"),(\"field_val\",\"string\",\"field_val\",\"string\"),(\"dq_dim\",\"string\",\"dq_dim\",\"string\"),(\"Dq_rule_result\",\"string\",\"Dq_rule_result\",\"string\"),(\"rule\",\"string\",\"rule\",\"string\")]\n",
    "        ## @return: target_frame_mapped\n",
    "        ## @inputs: [frame = <frame>]\n",
    "        target_frame_mapped = ApplyMapping.apply(frame = target_frame, mappings = [(\"processing_dttm\",\"string\",\"processing_dttm\",\"string\"),(\"data_source\",\"string\",\"data_source\",\"string\"),(\"dataset\",\"string\",\"dataset\",\"string\"),(\"data_domain\",\"string\",\"data_domain\",\"string\"),(\"key_nm\",\"string\",\"key_nm\",\"string\"),(key_nm,\"bigint\",\"key_value\",\"bigint\"),(\"field_nm\",\"string\",\"field_nm\",\"string\"),(field_nm,\"string\",\"field_val\",\"string\"),(\"dq_dim\",\"string\",\"dq_dim\",\"string\"),(\"Dq_rule_result\",\"string\",\"Dq_rule_result\",\"string\"),(\"rule\",\"string\",\"rule\",\"string\")], transformation_ctx = \"target_frame_mapped\")\n",
    "    \n",
    "        ## @type: DataSink\n",
    "        ## @args: [database = \"aroa-dw-pedro\", table_name = \"dq_target\", transformation_ctx = \"dataSink\"]\n",
    "        ## @return: dataSink\n",
    "        ## @inputs: [frame = target_frame_mapped]\n",
    "        dataSink = glueContext.write_dynamic_frame.from_catalog(frame = target_frame_mapped, database = \"aroa-dw-pedro\", table_name = \"dq_target\", transformation_ctx = \"dataSink\")\n",
    "\n",
    "job.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
